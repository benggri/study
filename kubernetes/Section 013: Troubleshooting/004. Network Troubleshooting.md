# Network Troubleshooting

## Weave Net

```bash
kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml
```

[https://kubernetes.io/docs/concepts/cluster-administration/addons/#networking-and-network-policy](https://kubernetes.io/docs/concepts/cluster-administration/addons/#networking-and-network-policy)

## Flannel 

```bash
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml
```

* Note: As of now flannel does not support kubernetes network policies.
* 참고: 현재 flannel은 kubernetes 네트워크 정책을 지원하지 않습니다.

## Calico 

```bash
curl https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/calico.yaml -O
kubectl apply -f calico.yaml
```

* In CKA and CKAD exam, you won't be asked to install the CNI plugin. But if asked you will be provided with the exact URL to install it.
* CKA 및 CKAD 시험에서는 CNI 플러그인을 설치하라는 메시지가 표시되지 않습니다. 그러나 요청하면 정확한 설치 URL이 제공됩니다.
* Note: If there are multiple CNI configuration files in the directory, the kubelet uses the configuration file that comes first by name in lexicographic order.
* 참고: 디렉터리에 여러 CNI 구성 파일이 있는 경우 kubelet은 사전순으로 이름이 먼저 나오는 구성 파일을 사용합니다.

## DNS in Kubernetes

* Kubernetes uses CoreDNS. CoreDNS is a flexible, extensible DNS server that can serve as the Kubernetes cluster DNS.
* Kubernetes는 CoreDNS를 사용합니다. CoreDNS는 Kubernetes 클러스터 DNS 역할을 할 수 있는 유연하고 확장 가능한 DNS 서버입니다.

### Memory and Pods

* In large scale Kubernetes clusters, CoreDNS's memory usage is predominantly affected by the number of Pods and Services in the cluster.
* 대규모 Kubernetes 클러스터에서 CoreDNS의 메모리 사용량은 주로 클러스터의 포드 및 서비스 수에 영향을 받습니다.
* Other factors include the size of the filled DNS answer cache, and the rate of queries received (QPS) per CoreDNS instance.
* 다른 요소로는 채워진 DNS 응답 캐시의 크기, CoreDNS 인스턴스당 수신된 쿼리 비율(QPS) 등이 있습니다.

* Kubernetes resources for coreDNS are:   
* coreDNS용 Kubernetes 리소스는 다음과 같습니다.
    1. a service account named coredns,
    1. cluster-roles named coredns and kube-dns
    1. clusterrolebindings named coredns and kube-dns, 
    1. a deployment named coredns,
    1. a configmap named coredns and a
    1. service named kube-dns.

* While analyzing the coreDNS deployment you can see that the the Corefile plugin consists of important configuration which is defined as a configmap.
* coreDNS 배포를 분석하는 동안 Corefile 플러그인이 configmap으로 정의된 중요한 구성으로 구성되어 있음을 확인할 수 있습니다.

* Port 53 is used for for DNS resolution.
* 포트 53은 DNS 확인에 사용됩니다.

```
kubernetes cluster.local in-addr.arpa ip6.arpa {
   pods insecure
   fallthrough in-addr.arpa ip6.arpa
   ttl 30
}
```

* This is the backend to k8s for cluster.local and reverse domains.
* 이것은 Cluster.local 및 역방향 도메인을 위한 k8s의 백엔드입니다.

```
proxy . /etc/resolv.conf
```

* Forward out of cluster domains directly to right authoritative DNS server.
* 클러스터 도메인에서 권한 있는 DNS 서버로 직접 전달합니다.

## Troubleshooting issues related to coreDNS

1. If you find CoreDNS pods in pending state first check network plugin is installed.
1. 보류 상태의 CoreDNS 포드를 발견하면 먼저 네트워크 플러그인이 설치되어 있는지 확인하세요.
1. coredns pods have CrashLoopBackOff or Error state
1. coredns 포드에 CrashLoopBackOff 또는 오류 상태가 있음
    * If you have nodes that are running SELinux with an older version of Docker you might experience a scenario where the coredns pods are not starting. To solve that you can try one of the following options:
    * 이전 버전의 Docker와 함께 SELinux를 실행하는 노드가 있는 경우 coredns 포드가 시작되지 않는 시나리오가 발생할 수 있습니다. 이 문제를 해결하려면 다음 옵션 중 하나를 시도해 보세요.
    1. Upgrade to a newer version of Docker.
        (최신 버전의 Docker로 업그레이드하세요.)
    1. Disable SELinux.
        (SELinux를 비활성화합니다.)
    1. Modify the coredns deployment to set **allowPrivilegeEscalation** to true:
        (허용PrivilegeEscalation을 true로 설정하도록 coredns 배포를 수정합니다.)
        ```
        kubectl -n kube-system get deployment coredns -o yaml | \
          sed 's/allowPrivilegeEscalation: false/allowPrivilegeEscalation: true/g' | \
          kubectl apply -f -
        ```
    1. Another cause for CoreDNS to have CrashLoopBackOff is when a CoreDNS Pod deployed in Kubernetes detects a loop.
    1. CoreDNS가 CrashLoopBackOff를 갖는 또 다른 원인은 Kubernetes에 배포된 CoreDNS Pod가 루프를 감지하는 경우입니다.
        1. There are many ways to work around this issue, some are listed here:
        1. Add the following to your kubelet config yaml: resolvConf: 
            <path-to-your-real-resolv-conf-file> This flag tells kubelet to pass an alternate resolv.conf to Pods. 
            For systems using systemd-resolved, /run/systemd/resolve/resolv.conf is typically the location of the "real" resolv.conf, although this can be different depending on your distribution.
        1. Disable the local DNS cache on host nodes, and restore /etc/resolv.conf to the original.
        1. A quick fix is to edit your Corefile, replacing forward . /etc/resolv.conf with the IP address of your upstream DNS, for example forward . 8.8.8.8. But this only fixes the issue for CoreDNS, kubelet will continue to forward the invalid resolv.conf to all default dnsPolicy Pods, leaving them unable to resolve DNS.
1. If CoreDNS pods and the kube-dns service is working fine, check the kube-dns service has valid endpoints.
    (CoreDNS 포드와 kube-dns 서비스가 제대로 작동하는 경우 kube-dns 서비스에 유효한 엔드포인트가 있는지 확인하세요.)
    ```
    kubectl -n kube-system get ep kube-dns
    ```
    * If there are no endpoints for the service, inspect the service and make sure it uses the correct selectors and ports.
    * 서비스에 대한 엔드포인트가 없는 경우 서비스를 검사하고 올바른 선택기와 포트를 사용하는지 확인하세요.